#!/usr/bin/env python3
"""
JSONCrack Watchdog
Monitors a JSON file in the project root and automatically calls json-generator.js
when new records are added.
"""

import json
import time
import subprocess
import os
import sys
from pathlib import Path
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import argparse
import logging
import threading

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('json-watchdog.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class JSONFileHandler(FileSystemEventHandler):
    """Handles file system events for JSON files."""
    
    def __init__(self, watch_file, generator_script):
        self.watch_file = Path(watch_file)
        self.generator_script = Path(generator_script)
        self.last_modified = 0
        self.last_content = None
        self.last_record_count = 0
        
        # Ensure the watch file exists
        if not self.watch_file.exists():
            self._create_initial_file()
        
        logger.info(f"üîç Watching file: {self.watch_file}")
        logger.info(f"üìú Generator script: {self.generator_script}")
    
    def _create_initial_file(self):
        """Create initial JSON file if it doesn't exist."""
        initial_data = {
            "records": [],
            "metadata": {
                "created": time.strftime("%Y-%m-%d %H:%M:%S"),
                "description": "Auto-generated by JSONCrack Watchdog"
            }
        }
        with open(self.watch_file, 'w') as f:
            json.dump(initial_data, f, indent=2)
        logger.info(f"‚úÖ Created initial file: {self.watch_file}")
    
    def _read_json_file(self):
        """Read and parse the JSON file."""
        try:
            with open(self.watch_file, 'r') as f:
                return json.load(f)
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Invalid JSON in {self.watch_file}: {e}")
            return None
        except FileNotFoundError:
            logger.warning(f"‚ö†Ô∏è File not found: {self.watch_file}")
            return None
    
    def _get_record_count(self, data):
        """Get the number of records in the JSON data."""
        if not data:
            return 0
        
        # Handle different JSON structures
        if isinstance(data, dict):
            if "records" in data:
                return len(data["records"])
            elif "users" in data:
                return len(data["users"])
            elif "data" in data:
                return len(data["data"])
            else:
                # Count top-level items if it's a simple object
                return len(data)
        elif isinstance(data, list):
            return len(data)
        else:
            return 0
    
    def _call_json_generator(self, json_data):
        """Call the JSON generator script with the provided data."""
        try:
            logger.info(f"üì§ Calling JSON generator with {self._get_record_count(json_data)} records")
            
            # Call the Node.js script directly with the original file
            result = subprocess.run([
                'node', str(self.generator_script),
                '--input-file', str(self.watch_file)
            ], capture_output=True, text=True, cwd=Path('src/tools/jsoncrack'))
            
            if result.returncode == 0:
                logger.info("‚úÖ JSON generator executed successfully")
                if result.stdout:
                    logger.info(f"üìã Output: {result.stdout.strip()}")
            else:
                logger.error(f"‚ùå JSON generator failed: {result.stderr}")
                
        except Exception as e:
            logger.error(f"‚ùå Error calling JSON generator: {e}")
    
    def on_modified(self, event):
        """Handle file modification events."""
        logger.info(f"üîç File system event detected: {event.src_path}")
        
        if event.is_directory:
            logger.info("üìÅ Event is for directory, ignoring")
            return
        
        if Path(event.src_path) != self.watch_file:
            logger.info(f"üìÑ Event is for different file: {event.src_path} != {self.watch_file}")
            return
        
        logger.info(f"‚úÖ File modification detected for watched file: {self.watch_file}")
        
        # Avoid duplicate events
        current_time = time.time()
        if current_time - self.last_modified < 1:  # Debounce for 1 second
            logger.info("‚è±Ô∏è  Debouncing event (too soon after last event)")
            return
        
        self.last_modified = current_time
        
        # Read the current content
        current_content = self._read_json_file()
        if current_content is None:
            return
        
        current_record_count = self._get_record_count(current_content)
        
        # Check if records were added
        if current_record_count > self.last_record_count:
            logger.info(f"üÜï New records detected! Count: {self.last_record_count} ‚Üí {current_record_count}")
            
            # Call the JSON generator
            self._call_json_generator(current_content)
            
            # Update our tracking
            self.last_record_count = current_record_count
            self.last_content = current_content
            
        elif current_record_count != self.last_record_count:
            logger.info(f"üìä Record count changed: {self.last_record_count} ‚Üí {current_record_count}")
            self.last_record_count = current_record_count
    
    def on_created(self, event):
        """Handle file creation events."""
        if Path(event.src_path) == self.watch_file:
            logger.info(f"üìÑ File created: {self.watch_file}")
            # Initialize tracking
            data = self._read_json_file()
            if data:
                self.last_record_count = self._get_record_count(data)
                self.last_content = data
    
    def on_deleted(self, event):
        """Handle file deletion events."""
        if Path(event.src_path) == self.watch_file:
            logger.warning(f"üóëÔ∏è File deleted: {self.watch_file}")

def main():
    """Main function to run the watchdog."""
    parser = argparse.ArgumentParser(description='JSONCrack Watchdog - Monitor JSON files and auto-generate')
    parser.add_argument(
        '--watch-file', 
        default='lineage_extraction_dumps/sql_agent_lineage.json',
        help='JSON file to watch (default: lineage_extraction_dumps/sql_agent_lineage.json)'
    )
    parser.add_argument(
        '--generator-script',
        default='src/tools/jsoncrack/json-generator.js',
        help='Path to the JSON generator script (default: src/tools/jsoncrack/json-generator.js)'
    )
    parser.add_argument(
        '--watch-dir',
        default='.',
        help='Directory to watch (default: current directory)'
    )
    
    args = parser.parse_args()
    
    # Resolve paths
    watch_dir = Path(args.watch_dir).resolve()
    watch_file = watch_dir / args.watch_file
    generator_script = Path(args.generator_script).resolve()
    
    # Validate paths
    if not watch_dir.exists():
        logger.error(f"‚ùå Watch directory does not exist: {watch_dir}")
        sys.exit(1)
    
    if not generator_script.exists():
        logger.error(f"‚ùå Generator script does not exist: {generator_script}")
        sys.exit(1)
    
    # Create event handler
    event_handler = JSONFileHandler(watch_file, generator_script)
    
    # Create observer
    observer = Observer()
    observer.schedule(event_handler, str(watch_dir), recursive=False)
    
    logger.info("üöÄ Starting JSONCrack Watchdog...")
    logger.info(f"üìÅ Watching directory: {watch_dir}")
    logger.info(f"üìÑ Watch file: {watch_file}")
    logger.info("üí° Add records to the JSON file to trigger auto-generation")
    logger.info("üõë Press Ctrl+C to stop")
    
    try:
        observer.start()
        logger.info("‚úÖ Observer started successfully")
        
        # Initialize tracking with current content
        data = event_handler._read_json_file()
        if data:
            event_handler.last_record_count = event_handler._get_record_count(data)
            event_handler.last_content = data
            logger.info(f"üìä Initial record count: {event_handler.last_record_count}")
        
        # Keep running with polling backup
        logger.info("üîÑ Watchdog loop started - monitoring for changes...")
        
        # Start polling thread as backup
        def poll_file():
            last_modified = event_handler.watch_file.stat().st_mtime if event_handler.watch_file.exists() else 0
            while True:
                try:
                    if event_handler.watch_file.exists():
                        current_modified = event_handler.watch_file.stat().st_mtime
                        if current_modified > last_modified:
                            logger.info(f"üìä Polling detected file change: {event_handler.watch_file}")
                            last_modified = current_modified
                            # Trigger the same logic as file system events
                            current_content = event_handler._read_json_file()
                            if current_content:
                                current_record_count = event_handler._get_record_count(current_content)
                                if current_record_count > event_handler.last_record_count:
                                    logger.info(f"üÜï Polling: New records detected! Count: {event_handler.last_record_count} ‚Üí {current_record_count}")
                                    event_handler._call_json_generator(current_content)
                                    event_handler.last_record_count = current_record_count
                                    event_handler.last_content = current_content
                except Exception as e:
                    logger.error(f"‚ùå Polling error: {e}")
                time.sleep(2)  # Poll every 2 seconds
        
        # Start polling in background
        poll_thread = threading.Thread(target=poll_file, daemon=True)
        poll_thread.start()
        logger.info("‚úÖ Polling backup started")
        
        while True:
            time.sleep(1)
            
    except KeyboardInterrupt:
        logger.info("üõë Stopping watchdog...")
        observer.stop()
    
    observer.join()
    logger.info("‚úÖ Watchdog stopped")

if __name__ == "__main__":
    main() 